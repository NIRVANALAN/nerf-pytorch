{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm, trange\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "dataset = 'chairs'\n",
    "srn_base_train = f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRN dataset /mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/chairs_train name: chairs\n",
      "Loading SRN dataset /mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/chairs_train_test name: chairs\n"
     ]
    }
   ],
   "source": [
    "train_set, train_test = get_split_dataset(\n",
    "    'srn', srn_base_train, split=[\"train\", \"train_test\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2151"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'img_id', 'focal', 'c', 'images', 'masks', 'bbox', 'poses'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_test[0]['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d61829490>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True)\n",
    "fc = model.fc\n",
    "model.fc=nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "tensor_img = img.permute(2,0,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-830d941538c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(external_dataset[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{dataset}_train_test/'\n",
    "dst_path=f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{dataset}_pool/'\n",
    "# os.mkdir(dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrins = sorted(\n",
    "    glob.glob(os.path.join(base_path, \"*\", \"intrinsics.txt\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/chairs_train_test/1007e20d5e811b308351982a6e40cf41/intrinsics.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2151/2151 [11:27<00:00,  3.13it/s]\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "\n",
    "for intrin_path in tqdm(intrins[:]):\n",
    "    dir_path = os.path.dirname(intrin_path)\n",
    "    uid = dir_path.split('/')[-1]\n",
    "    rgb_paths = sorted(glob.glob(os.path.join(dir_path, \"rgb\", \"*.png\")))\n",
    "    rand_idx = random.choices(list(range(len(rgb_paths))), k=25)\n",
    "    select_rgbs = [rgb_paths[i] for i in rand_idx]\n",
    "    \n",
    "    Path(dst_path + '/{}'.format(uid)).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for rgb_path in select_rgbs:\n",
    "        \n",
    "        shutil.copy(rgb_path, dst_path+'{}/{:07}.png'.format(uid, idx))\n",
    "        idx+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "dst_path_v0='/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{}_pool/'.format(dataset)\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "#         transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.9084, 0.9045, 0.9019], std=[0.2319, 0.2415, 0.2483] # chairs\n",
    "#             mean = [0.9052, 0.8945, 0.8894], std=[0.2232, 0.2390, 0.2472] # cars\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "external_dataset = datasets.ImageFolder(root=dst_path, transform=data_transform)\n",
    "len(external_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2norm = Normalize(2)\n",
    "\n",
    "for idx in range(10):\n",
    "    train_instance=train_set[idx]\n",
    "    imgs = train_instance['images'].permute(0,3,1,2).float()\n",
    "    norm_imgs = data_transform(imgs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = l2norm(model(norm_imgs))\n",
    "        \n",
    "    torch.save(feats, Path(train_instance['path']) / 'feats.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0_feats = torch.load(Path(train_set[0]['path']) / 'feats.pt')\n",
    "d_path = Path(f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{dataset}_pool_sub/{dsize}')\n",
    "mb_chairs = torch.load(d_path / 'memory_bank.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2048])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_chairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = torch.utils.data.DataLoader(external_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.util import calculate_mean_std\n",
    "mean, std = calculate_mean_std(dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_bank = torch.zeros(len(external_dataset), 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "labels = np.zeros((len(external_dataset)))\n",
    "l2norm = Normalize(2)\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dataset_loader):\n",
    "        data, label = data\n",
    "#         out = model(data)\n",
    "#         out = l2norm(out)\n",
    "# #         ipdb.set_trace()\n",
    "#         memory_bank[idx:idx+data.size(0)] = out\n",
    "        labels[idx:idx+data.size(0)]=label\n",
    "        idx += data.size(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memory_bank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-42ff108a5c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_bank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{}_pool_memory_bank.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'memory_bank' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(memory_bank, '/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{}_pool_memory_bank.pt'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = CIFAR10(root='~/Dataset/CIFAR10', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "# ! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class_idx = json.load(open('imagenet_class_index.json'))\n",
    "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hook'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loafer\n",
      "pencil_sharpener\n",
      "megalith\n",
      "vault\n",
      "monitor\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-15970e0df134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for idx in out[0].sort()[1][-10:]:\n",
    "    print(idx2label[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(data, label, title):\n",
    "    x_min, x_max = np.min(data, 0), np.max(data, 0)\n",
    "    data = (data - x_min) / (x_max - x_min)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.text(data[i, 0], data[i, 1], str(label[i]),\n",
    "                 color=plt.cm.Set1(label[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idices = np.load(f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/chairs_pool_sub/10000/idx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mnt/lustre/yslan/Repo/NVS/Projects/volume_rendering/srn_dataset/{dataset}_pool_sub/{dsize}/paths.txt', 'r') as f:\n",
    "    paths = [i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emsemble_feat = torch.mean(id0_feats[1:4], 0, keepdim=True)[0]\n",
    "emsemble_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6625)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emsemble_feat.dot(id0_feats[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = emsemble_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = mb_chairs @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_sim = torch.argsort(sim, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6897, 0.6890, 0.6887,  ..., 0.6054, 0.6049, 0.5901])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim[ordered_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ordered_sim, 'debug/ordered_sim_1w.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f'{1}'+('a' if False else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Linear(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-6965c97fe589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach()."
     ]
    }
   ],
   "source": [
    "l.weight[:3].requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('./logs/PIXNERF/SRN/Y/Chairs/AE_PT/9views_Y_AE_PT_id0_uniform_1w_pt_newY/099.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt['encoder'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_dir=Path('/mnt/lustre/share/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt = Path('/mnt/lustre/share/images/meta/val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_txt) as val_f:\n",
    "    val_imgs = [i.strip() for i in val_f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: /mnt/lustre/share/images/val\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-555076d1d30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgnet_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgnet_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     ):\n\u001b[0;32m--> 226\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    227\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Supported extensions are: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: /mnt/lustre/share/images/val\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
     ]
    }
   ],
   "source": [
    "imgnet_val = torchvision.datasets.ImageFolder(imgnet_dir / 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: /mnt/lustre/share/images/val\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-3fbfe76687a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimagenet_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m data_loader = torch.utils.data.DataLoader(\n",
      "\u001b[0;32m~/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     ):\n\u001b[0;32m--> 226\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    227\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Supported extensions are: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: /mnt/lustre/share/images/val\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
     ]
    }
   ],
   "source": [
    "val_path = imgnet_dir / 'val'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "imagenet_data = torchvision.datasets.ImageFolder(val_path, transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    imagenet_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "labels = np.zeros((len(external_dataset)))\n",
    "l2norm = Normalize(2)\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dataset_loader):\n",
    "        data, label = data\n",
    "#         out = model(data)\n",
    "#         out = l2norm(out)\n",
    "# #         ipdb.set_trace()\n",
    "#         memory_bank[idx:idx+data.size(0)] = out\n",
    "        labels[idx:idx+data.size(0)]=label\n",
    "        idx += data.size(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(torch.Tensor.item, [torch.Tensor([5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 31 16:51:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    36W / 250W |   1456MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    25W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    26W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:09:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    24W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    26W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     22243      C   ...lustre/yslan/local/anaconda3/bin/python  1445MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbaseconda05fe16f9363d487dbdc6b533b6b86ac4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
